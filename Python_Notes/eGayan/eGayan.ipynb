{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee8eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Jan  4 17:20:10 2022\n",
    "\n",
    "@author: sarfaraz\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdca0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_proj_folder(folder):\n",
    "    '''\n",
    "    create_proj_folder (storage_folder)\n",
    "    '''\n",
    "    if not os.path.exists(folder):\n",
    "        print('Creating project folder : {}'.format(folder))\n",
    "        os.makedirs(folder)\n",
    "        print('Created project folder : {}'.format(folder))\n",
    "        \n",
    "def file_download(title, collection, link):\n",
    "    try:\n",
    "        create_proj_folder(\"StudyMaterials\\\\\" + collection + \"\\\\\")\n",
    "        r2 = requests.get(link, verify=False)\n",
    "        with open(\"StudyMaterials\\\\\" + collection + \"\\\\\" +title+\".pdf\", \"wb\") as f:\n",
    "            f.write(r2.content)\n",
    "        print('Files downloaded.')\n",
    "    except Exception as e:\n",
    "        print('Files download failed. {}'.format(e.args))\n",
    "        \n",
    "def parser(url):\n",
    "    r = requests.get(url, verify=False)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    for link in soup.find_all('a',{'class':'btn btn-primary'}):\n",
    "        # print(\"https://www.egyankosh.ac.in/\"+ link.get('href'))\n",
    "        title = soup.title.text.replace(\"eGyanKosh: \",\"\").replace(\":\",\"_\")\n",
    "        table = soup.find(\"table\",{\"class\": \"table itemDisplayTable\"})\n",
    "        table_data = table.find_all(\"tr\")  # contains 2 rows\n",
    "        \n",
    "        # print(len(table_data))\n",
    "        # Get all the headings of Lists\n",
    "        collection = [td.text for td in table_data[len(table_data)-1].find_all(\"td\")[1] if td.text != ''][0].replace(\":\",\"_\")\n",
    "        link = \"https://www.egyankosh.ac.in\" + link.get('href')\n",
    "    return title, collection, link\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c16f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data file\n",
    "df = pd.read_excel(\"MEC.xlsx\")\n",
    "print(df.columns)\n",
    "\n",
    "for url in df[\"DocLink\"]:\n",
    "    \n",
    "    # get download links\n",
    "    title, collection, link = parser(url)\n",
    "    print (title, collection)\n",
    "    \n",
    "    # file download\n",
    "    file_download(title, collection, link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
