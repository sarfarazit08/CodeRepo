{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning In Python\n",
    "\n",
    "## Table Of Content\n",
    "\n",
    "1. Head First into Deep Learning\n",
    "        1.1 The Course Overview\n",
    "        1.2 What Is Deep Learning\n",
    "        1.3 Open Source Libraries for Deep Learning\n",
    "        1.4 Deep Learning \"Hello World!\" Classifying the MNIST Data \n",
    "\n",
    "2. Backpropagation and Theano for the Rescue\n",
    "        2.1 Introduction to Backpropagation\n",
    "        2.2 Understanding Deep Learning with Theano\n",
    "        2.3 Optimizing a Simple Model in Pure Theano\n",
    "\n",
    "3. Keras  Making Theano Even Easier to Use\n",
    "        3.1 Keras Behind the Scenes.mp4\n",
    "        3.2 Fully Connected or Dense Layers.\n",
    "        3.3 Convolutional and Pooling Layers\n",
    "    \n",
    "4. Solving Cats Versus Dogs\n",
    "        4.1 Large Scale Datasets, ImageNet, and Very Deep Neural Networks\n",
    "        4.2 Loading Pre-trained Models with Theano\n",
    "        4.3 Reusing Pre-trained Models in New Applications\n",
    "\n",
    "5. \"for\" Loops and Recurrent Neural Networks in Theano\n",
    "        5.1 Theano for Loops  the scan Module\n",
    "        5.2 Recurrent Layers\n",
    "        5.3 Recurrent Versus Convolutional Layers\n",
    "        5.4 Recurrent Networks Training a Sentiment Analysis Model for Text\n",
    "\n",
    "6. Bonus Challenge and TensorFlow\n",
    "        6.1 Bonus Challenge  Automatic Image Captioning\n",
    "        6.2 Captioning TensorFlow  Googles Machine Learning Library\n",
    "        \n",
    "## Prerequisites \n",
    "\n",
    "* Python\n",
    "* Calculus and linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Head First into Deep Learning\n",
    "\n",
    "### 1.1 The Course Overview\n",
    "\n",
    "<img src=\"NN.png\" alt=\"Neural Network\" width=\"70%\" Height=\"70%\" align=\"left\"/>\n",
    "<img src=\"NN1.png\" alt=\"Neural Network\" width=\"70%\" Height=\"70%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What is Deep Learning?\n",
    "\n",
    "<img src=\"NN2.png\" alt=\"Neural Network\" width=\"70%\" Height=\"70%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Open Source Libraries for Deep Learning\n",
    "\n",
    "#### Desired Features of Deep Learning Framework \n",
    "\n",
    "* Covers the main architectures (fully connected, convolutional, and recurrent) \n",
    "* Flexible and fast prototyping \n",
    "* Compile to run on GPU \n",
    "\n",
    "#### Deep Learning Libraries and Python APIs\n",
    "\n",
    "* Caffe\n",
    "* Keras\n",
    "* Theano\n",
    "* TensorFlow\n",
    "* Lasagne\n",
    "* Blocks\n",
    "* Neon\n",
    "* Chainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Deep Learning \"Hello World!\" Classifying the MNIST Data\n",
    "\n",
    "#### Environment Set Up\n",
    "\n",
    "* Download and install Anaconda Python distribution for free from [here](http://docs.continuum.io/anaconda/install)\n",
    "* Update Theano \n",
    "    * Command line:\n",
    "        * `conda uninstall Theano`\n",
    "        * `pip install Theano`\n",
    "\n",
    "    * Learn how to configure Theano [here](http://deeplearning.net/software/theano/library/config.html)\n",
    "* Install Keras \n",
    "    * Command line:\n",
    "        * `conda uninstall Keras`\n",
    "        * `pip install Keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 1, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "One hot encoding : [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "nb_classes = 10   # 10 digits from 0-9\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# The data, shuffled and split between train and test sets.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshapes data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Converts class vectors to binary class matrices.\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"One hot encoding : {}\".format(y_train[0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19d70748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first 9 image samples from dataset\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3, i+1)\n",
    "    plt.imshow(x_train[i, 0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "<img src=\"ModelDefinition.png\" alt=\"model definition\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 1 for 'conv2d_5/convolution' (op: 'Conv2D') with input shapes: [?,1,28,28], [5,5,28,6].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_5/convolution' (op: 'Conv2D') with input shapes: [?,1,28,28], [5,5,28,6].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1f7af435451c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3162\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3164\u001b[0;31m         data_format='NHWC')\n\u001b[0m\u001b[1;32m   3165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_postprocess_conv2d_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         op=op)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mwith_space_to_batch\u001b[0;34m(input, dilation_rate, padding, op, filter_shape, spatial_dims, data_format)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dilation_rate must be positive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconst_rate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_spatial_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[1;31m# We have two padding contributions. The first is used for converting \"SAME\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(input_converted, _, padding)\u001b[0m\n\u001b[1;32m    662\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m           \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     return with_space_to_batch(\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_non_atrous_convolution\u001b[0;34m(input, filter, padding, data_format, strides, name)\u001b[0m\n\u001b[1;32m    129\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mconv_dims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"NDHWC\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                                 \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    398\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sarfu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_5/convolution' (op: 'Conv2D') with input shapes: [?,1,28,28], [5,5,28,6]."
     ]
    }
   ],
   "source": [
    "# Building a Sequential Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6, (5, 5), input_shape=(1,img_rows,img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16,(5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(120,(5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(84))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
