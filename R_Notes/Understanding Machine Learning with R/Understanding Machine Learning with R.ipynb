{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Overview\n",
    "\n",
    "+ What is Machine Learning? \n",
    "+ Machine Learning vs Traditional Development \n",
    "+ Types of Machine Learning \n",
    "+ Course Content \n",
    "+ Machine Learning and Data Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning in Action \n",
    "\n",
    "+ Is this email spam? \n",
    "+ How will people vote? \n",
    "+ What will people buy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Traditional Control Logic |-|Machine Learning Logic| \n",
    "|-|-|-|\n",
    "|If > Case> While> Until|-|Data> Algorithm > Data Analysis > Model|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "\n",
    "Building a model from example inputs to make data-driven predictions vs. following strictly static program instructions. \n",
    "\n",
    "### Types of Machine Learning : \n",
    "1. Supervised Machine Learning\n",
    "2. Unsupervised Machine Learning\n",
    "3. Reinforcement Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Technique Comparison \n",
    "|Supervised |Unsupervised |\n",
    "|-|-|\n",
    "|Value prediction |Identify clusters of like data |\n",
    "|Needs training data containing value being predicted|Data does not contain cluster membership |\n",
    "|Trained model predicts value in new data|Model provides access to data by cluster |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Machine Learning With R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills Required\n",
    "\n",
    "+ Software development experience\n",
    "+ Experience with data in tables\n",
    "+ Basic math and statistics skills\n",
    "+ Passion to understand\n",
    "\n",
    "### Why This Course? \n",
    "\n",
    "+ Add Machine Learning skills \n",
    "+ Learn something new\n",
    "+ Learn about Data Science\n",
    "\n",
    "<img src=\"http://2s7gjr373w3x22jf92z99mgm5w.wpengine.netdna-cdn.com/wp-content/uploads/2016/01/data-science-venn-diagram.png\" alt=\"Data Science\" height=\"50%\" width=\"50%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Workflow \n",
    "\n",
    "An **orchestrated and repeatable** pattern which systematically transforms and processes information to create prediction solutions. \n",
    "\n",
    "1. Asking the right question\n",
    "1. Preparing data\n",
    "1. Selecting the algorithm\n",
    "1. Training the model\n",
    "1. Testing the model\n",
    "\n",
    "\n",
    "<img src=\"https://www.class-central.com/report/app/uploads/2017/05/ml-workflow.jpg\" alt=\"Data Science\" height=\"50%\" width=\"50%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning workflow, via [UpX Academy](https://upxacademy.com/introduction-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Workflow Guidelines \n",
    "+ Early steps are most important (Each step depends on previous steps)\n",
    "+ Expect to go backwards (Later knowledge effects previous steps)\n",
    "+ Data is never as you need it (Data will have to be altered)\n",
    "+ More data is better (More Data => Better Results )\n",
    "+ Don't pursue a bad solution (Reevaluate, fix or quit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Asking the Right Question\n",
    "\n",
    "1. Don't we  already have the question? \n",
    "    + \"Predict if a flight will be on-time\" \n",
    "    + But we need statement to direct and validate work \n",
    "    + Define End Goal, Starting Point and How to Achieve Goal\n",
    "2. Solution Statement Goals \n",
    "    + Define scope (including data sources) \n",
    "    + Define target performance \n",
    "    + Define context for usage \n",
    "    + Define how solution will be created\n",
    "3. Scope and Data Sources \n",
    "    + US flights only \n",
    "    + Flights between US airports only \n",
    "    + DOT database is a good source \n",
    "    + \"Using DOT data, predict if a flight would be on time\"\n",
    "4. Data\n",
    "    + Preliminary data review \n",
    "    + Delays tracked, not on-time\n",
    "    + \"Using DOT data, predict if a flight would be delayed\"\n",
    "5. Performance Targets\n",
    "    + Binary result (True or False) \n",
    "    + Coin Flip 50% Accuracy \n",
    "    + 70% Accuracy is common target \n",
    "    + \"Using DOT data, predict with 70+% accuracy if a flight would be delayed\"\n",
    "6. Context \n",
    "    + Data driven results \n",
    "    + DOT \"delayed\" greater than 15 minutes after scheduled \n",
    "    + \"Using DOT data, predict with 70+% accuracy if a flight would arrive 15+ minutes after the scheduled arrival time.\"\n",
    "7. Solution Creation\n",
    "    + Machine Learning Workflow \n",
    "        + Process DOT data \n",
    "        + Transform data as required \n",
    "\n",
    "**\"Use the Machine Learning Workflow to process and transform DOT data to create a prediction model. This model must predict whether a flight would arrive 15+ minutes after the scheduled arrival time with 70+% accuracy.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Preparing Your Data\n",
    "\n",
    "1. Find the data we need \n",
    "1. Inspect and clean the data \n",
    "1. Explore the data \n",
    "1. Mold the data to Tidy data \n",
    "\n",
    "#### Tidy Data \n",
    "\n",
    "+ Tidy datasets are easy to manipulate, model and visualize, and have a specific structure. ***-- Hadley Wickham***\n",
    "    + each **variable** is a **column**\n",
    "    + each **observation** is a **row** \n",
    "    + each type of **observational unit** is a **table**. \n",
    "+ 50-80% of a ML project is spent getting, cleaning, and organizing data.\n",
    "\n",
    "#### Getting Data\n",
    "\n",
    "+ Google \n",
    "+ Government databases \n",
    "+ Professional or company data sources \n",
    "+ Your company \n",
    "+ Your department \n",
    "+ All of the above\n",
    "\n",
    "#### Data Rules\n",
    "\n",
    "1. Closer the data is to what you are predicting, the better.\n",
    "2. Data will never be in the format you need.\n",
    "3. Accurately predicting rare event is difficult\n",
    "4. Track how you manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleanup Demo\n",
    "\n",
    "+ **DOT(Department of Transportation, US)** collects on-time data, so on-time data is available. Get DOT on-time data from [here](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time).\n",
    "\n",
    "+ Check these columns and click \"download\" to download the data in Zip format and extract the CSV file to a folder.\n",
    "\n",
    "|Columns|Columns|\n",
    "|-|-|\n",
    "|DAY_OF_MONTH|DEST_AIRPORT_SEQ_ID| \n",
    "|DAY_OF_WEEK|DEST| \n",
    "|UNIQUE_CARRIER|DEP_TIME| \n",
    "|CARRIER|DEP_DEL15| \n",
    "|TAIL_NUM|DEP_TIME_BLK| \n",
    "|FL_NUM|ARR_TIME| \n",
    "|ORIGIN_AIRPORT_ID|ARR_DEL15| \n",
    "|ORIGIN_AIRPORT_SEQ_ID|CANCELLED| \n",
    "|ORIGIN|DIVERTED| \n",
    "|DEST_AIRPORT_ID|DISTANCE|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "data <- read.csv2('./data/Jan2015_ontime_data.csv', header = TRUE, sep = ',', stringsAsFactors = FALSE)\n",
    "\n",
    "# find the no. of records\n",
    "nrow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "names(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a vector having specific 3-charachter airport codes \n",
    "# It will be used to filter related records\n",
    "airports <- c('ATL','LAX','ORD','DFW','JFK','SFO','CLT','LAS','PHX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset records\n",
    "data <- subset(data, DEST %in% airports & ORIGIN %in% airports)\n",
    "\n",
    "# find the no. of records\n",
    "nrow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "head(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "tail(data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Both head and tail show that 'X' column is added as part of csv import and has no values so it can be discarded.\n",
    "We can set that column value to NULL to discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$X <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data again\n",
    "head(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data again\n",
    "tail(data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This time 'X' column is discarded now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns to Eliminate\n",
    "\n",
    "+ Not used \n",
    "+ No values \n",
    "+ Duplicates \n",
    "+ Correlated Columns\n",
    "    + Same information in a different format,e.g., ID and value associated with ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding correlation, 1 -> means perfect correlation\n",
    "cor(data[c('ORIGIN_AIRPORT_ID', 'ORIGIN_AIRPORT_SEQ_ID')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding correlation, 1 -> means perfect correlation\n",
    "cor(data[c('DEST_AIRPORT_ID', 'DEST_AIRPORT_SEQ_ID')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'ORIGIN_AIRPORT_ID' and 'ORIGIN_AIRPORT_SEQ_ID' are correlated and so do 'DEST_AIRPORT_ID' and 'DEST_AIRPORT_SEQ_ID'.\n",
    "So, we'll drop 'ORIGIN_AIRPORT_SEQ_ID' and 'DEST_AIRPORT_SEQ_ID' from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$ORIGIN_AIRPORT_SEQ_ID <- NULL\n",
    "data$DEST_AIRPORT_SEQ_ID <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "head(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "tail(data, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the columns are dropped now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for mismatch\n",
    "mismatched_rows <- data[data$CARRIER != data$UNIQUE_CARRIER, ]\n",
    "nrow(mismatched_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that there are no mismatched rows that means these columns are identical too. so we can drop 'UNIQUE_CARRIER'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$UNIQUE_CARRIER <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data again\n",
    "head(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data again\n",
    "tail(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On-Time Data\n",
    "on_time_data <- data[!is.na(data$ARR_DEL15) & !is.na(data$DEP_DEL15) & data$ARR_DEL15 != \"\" & data$DEP_DEL15 != \"\" , ]\n",
    "nrow(on_time_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string column values to integer - distance, cancelled, diverted columns etc.\n",
    "on_time_data$DISTANCE <- as.integer(on_time_data$DISTANCE)\n",
    "on_time_data$CANCELLED <- as.integer(on_time_data$CANCELLED)\n",
    "on_time_data$DIVERTED <- as.integer(on_time_data$DIVERTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorise columns to view distinct types of values \n",
    "\n",
    "on_time_data$CARRIER <- as.factor(on_time_data$CARRIER )\n",
    "on_time_data$DEP_TIME_BLK <- as.factor(on_time_data$DEP_TIME_BLK )\n",
    "on_time_data$ORIGIN <- as.factor(on_time_data$ORIGIN )\n",
    "on_time_data$DEST <- as.factor(on_time_data$DEST )\n",
    "on_time_data$DAY_OF_WEEK <- as.factor(on_time_data$DAY_OF_WEEK )\n",
    "on_time_data$ORIGIN_AIRPORT_ID <- as.factor(on_time_data$ORIGIN_AIRPORT_ID )\n",
    "on_time_data$DEST_AIRPORT_ID <- as.factor(on_time_data$DEST_AIRPORT_ID )\n",
    "on_time_data$ARR_DEL15 <- as.factor(on_time_data$ARR_DEL15 )\n",
    "on_time_data$DEP_DEL15 <- as.factor(on_time_data$DEP_DEL15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On-time and delayed flights records\n",
    "tapply(on_time_data$ARR_DEL15, on_time_data$ARR_DEL15, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of delayed flights\n",
    "delayed_flight_percentage <- (6460 / (25664+ 6460)) * 100\n",
    "delayed_flight_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Selecting Your Algorithm\n",
    "\n",
    "+ Role of algorithm \n",
    "+ Perform algorithm selection \n",
    "    + Use solution statement to filter algorithms \n",
    "    + Discuss best algorithms \n",
    "    + Select one initial algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/role_of_algorithm.png' alt='role_of_algorithm' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Selection\n",
    "\n",
    "+ Compare factors \n",
    "+ Difference of opinions about which factors are important \n",
    "+ You will develop your own factors \n",
    "\n",
    "#### Algoritm Decision Factors\n",
    "\n",
    "+ Learning Type \n",
    "    + \"Use the Machine Learning Workflow to process and transform DOT data to create a prediction model. This model must predict whether a flight would arrive 15+ minutes after the scheduled arrival time with 70+% accuracy.' \n",
    "    + Prediction Model => Supervised machine learning \n",
    "+ Result Type\n",
    "    + Regression \n",
    "        + Continuous values \n",
    "        + price = A * # bedroom + B * size etc.\n",
    "    + Classification \n",
    "        + Discrete values \n",
    "        + small, medium, large \n",
    "        + 1-100, 101-200, 201-300 \n",
    "        + true or false\n",
    "     + \"... predict whether a flight would arrive 15+ minutes after the scheduled arrival time.\"\n",
    "        + ARR_DEL15 -> Binary (TRUE/FALSE) \n",
    "        + Algorithm must support classification \n",
    "        + Binary classification\n",
    "+ Complexity\n",
    "    + Keep it Simple \n",
    "    + Eliminate \"ensemble\" algorithms \n",
    "        + Container algorithm \n",
    "        + Multiple child algorithms \n",
    "        + Boost performance \n",
    "        + Can be difficult to debug\n",
    "+ Basic vs enhanced\n",
    "    + Enhanced \n",
    "        + Variation of Basic \n",
    "        + Performance improvements \n",
    "        + Additional functionality \n",
    "        + More complex \n",
    "    + Basic \n",
    "        + Simpler \n",
    "        + Easier to understand\n",
    "\n",
    "#### Candidate Algorithms\n",
    "\n",
    "+ Naive Bayes\n",
    "    + Based on likelihood and probability \n",
    "    + Every feature has the same weight \n",
    "    + Requires smaller amount of data\n",
    "+ Logistic Regression\n",
    "    + Confusing name, gives binary result \n",
    "    + Relationship between features are weighted\n",
    "+ Decision Trees\n",
    "    + Binary Tree \n",
    "    + Node contains decision \n",
    "    + Requires enough data to determine nodes and splits\n",
    "\n",
    "#### Selected Algorithm  -> Logistic Regression\n",
    "\n",
    "+ Simple - easy to understand \n",
    "+ Fast - up to 100X faster \n",
    "+ Stable to data changes \n",
    "\n",
    "#### Summary\n",
    "\n",
    "+ Lots of algorithms available \n",
    "+ Selection based on \n",
    "    + Learning -> Supervised \n",
    "    + Result -> Binary classification \n",
    "    + Non-ensemble \n",
    "    + Basic\n",
    "+ Logistic Regression selected for training \n",
    "    + Simple, fast, and stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Training the Model\n",
    "\n",
    "+ Understand the training process\n",
    "+ Caret package\n",
    "+ Train algorithm with DOT data\n",
    "\n",
    "**Machine Learning Training**: Letting specific data teach a Machine Learning algorithm to create a specific forecast model.\n",
    "\n",
    "**Why Retrain?**: \n",
    "\n",
    "+ New data better predictions \n",
    "+ Verify training performance with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/training.png' alt='training model' height=\"50%\" width=\"50%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Training Features\n",
    "\n",
    "+ We want minimum features (columns) \n",
    "+ Selected features \n",
    "    + Origin and Destination \n",
    "    + Day Of Week \n",
    "    + Carrier \n",
    "    + Departure Time Block \n",
    "    + Arrival Delay 15 (required)\n",
    "\n",
    "#### CARET (Classification And Regression Training)\n",
    "\n",
    "+ Caret - R package\n",
    "+ Toolset for training and evaluation tasks \n",
    "    + Data splitting \n",
    "    + Pre-processing \n",
    "    + Feature selection \n",
    "    + Model tuning \n",
    "+ Common interface across algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages('caret', repos = 'https://cran.r-project.org/')\n",
    "# install.packages('e1071', repos = 'https://cran.r-project.org/', dependencies=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require('caret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Algorithms can use random numbers in training. \n",
    "+ The random number sequence is based on a seed number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to generate exact same set of data frames\n",
    "set.seed(122515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features which will be used for prediction\n",
    "features <- c('ARR_DEL15','DAY_OF_WEEK','CARRIER','DEST','ORIGIN', 'DEP_TIME_BLK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data frame based on features\n",
    "filtered_ontime_data <- on_time_data[,features]\n",
    "\n",
    "# check the names of column in data frame to be sure it's filted\n",
    "names(filtered_ontime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Data Splitting Requirements \n",
    "    + Divide into two data frames by user specified % \n",
    "    + Ensure 'ARR_DEL15' ratio of true to false is preserved in training and testing data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Training and Test Data\n",
    "\n",
    "training_rows <- createDataPartition(filtered_ontime_data$ARR_DEL15, p=0.70, list = FALSE)\n",
    "\n",
    "training_data <- filtered_ontime_data[training_rows,] #select training rows\n",
    "test_data <- filtered_ontime_data[-training_rows,] # select other than training rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check percentage of rows in each dataset\n",
    "nrow(training_data)/(nrow(training_data)+ nrow(test_data))*100\n",
    "nrow(test_data)/(nrow(training_data)+ nrow(test_data))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training algorithm with training data to create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_model <- train(ARR_DEL15 ~ . , data = training_data, method = 'glm', family = 'binomial')\n",
    "\n",
    "# check some stats about trained model\n",
    "logistic_reg_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Testing Your Model's Accuracy\n",
    "\n",
    "+ Evaluate the model against test data \n",
    "+ Interpret results \n",
    "+ Improve results \n",
    "\n",
    "**Note**: Statistics are only data. We define what is good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the delyed flight based on the trained model using test data set\n",
    "prediction <- predict(logistic_reg_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate confusion matrix to find the prediction models capabilities\n",
    "confusion_matrix <- confusionMatrix(prediction, test_data[, 'ARR_DEL15'])\n",
    "confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **Confusion Matrix** we found that:\n",
    "+ Delayed flights not being predicted \n",
    "+ Need to increase prediction accuracy \n",
    "+ What are our options? \n",
    "    + Improving data quality\n",
    "    + Selecting the algorithm which performs better\n",
    "    + Training the model which provides more accurate results\n",
    "\n",
    "#### Options for Improving performance (Round - 1)\n",
    "\n",
    "+ Add additional columns \n",
    "    + DEP_DEL15\n",
    "    + Will predict arrival delay \n",
    "    + Departure delay detected late \n",
    "    + May not be useful predictor \n",
    "+ Adjust training settings \n",
    "    + It improves the performance slightly which is not very effective in this case\n",
    "+ Select a better algorithm (Ensamble algorithm)\n",
    "    + Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction using Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random forest model\n",
    "# training_data[-1] -> means excluding the first column i.e., 'ARR_DEL15'\n",
    "rf_model <- randomForest(training_data[-1], training_data$ARR_DEL15, proximity = TRUE, importance = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the delyed flight based on the trained model using test data set\n",
    "prediction <- predict(rf_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate confusion matrix to find the prediction models capabilities\n",
    "confusion_matrix <- confusionMatrix(prediction, test_data[, 'ARR_DEL15'])\n",
    "confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options for Improving performance (Round - 2) \n",
    "\n",
    "+ Adjust training settings \n",
    "+ Select a better algorithm \n",
    "+ Rethink the problem \n",
    "    + What causes delays? \n",
    "    + Subject knowledge required? \n",
    "    + Research shows weather is a delay factor\n",
    "    \n",
    "#### Performance Improvement Cycle\n",
    "\n",
    "+ Change data, settings, algorithm or all of the above \n",
    "+ Improve each cycle \n",
    "+ The difficult part is knowing when to stop\n",
    "\n",
    "#### Summary\n",
    "\n",
    "+ Evaluated Logistic Regression model \n",
    "    + predict() \n",
    "    + confusionMatrix() \n",
    "+ Improved performance using Random Forest algorithm \n",
    "+ Defined future improvements incorporating weather data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Points\n",
    "\n",
    "+ Machine Learning is here today\n",
    "+ Machine Learning is data driven\n",
    "+ Follow the Machine Learning Workflow\n",
    "    + Ask the right questions\n",
    "        + Started with question\n",
    "        + Used requirements and knowledge to transform\n",
    "        + Resulted in solution statement\n",
    "    + Preparing data\n",
    "        + Retrieved data from DOT site\n",
    "        + Cleaned data\n",
    "        + Molded data        \n",
    "    + Selecting the algorithm\n",
    "        + Learning type\n",
    "        + Result type\n",
    "        + Complexity\n",
    "        + Basic vs. Enhanced\n",
    "    + Training the model\n",
    "        + Split data - 70%/30% (training data/test data)\n",
    "        + Trained with training data\n",
    "    + Testing the model\n",
    "        + Predicted with test data\n",
    "        + Evaluated Prediction\n",
    "        + Switched to Random Forest\n",
    "        + Evaluated Random Forest\n",
    "        + Considered adding weather data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
